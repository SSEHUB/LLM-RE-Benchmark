import DataLoader as dl
import pandas as pd
import re

from typing import List, Dict, Set

# Ergebnis-Dictionary
text_analysis_results = {}



def count_words(text: str) -> int:
    """
    ZÃ¤hlt die Anzahl der WÃ¶rter in einem gegebenen Text.
    """
    if not text:
        return 0
    return len(re.findall(r'\b\w+\b', text))



def count_characters(text: str) -> int:
    """
    ZÃ¤hlt die Anzahl der Zeichen in einem gegebenen Text.
    """
    if not text:
        return 0
    return len(text)



def count_reference_words(requirements: Dict[str, Dict]) -> int:
    """
    Summiert die Wortanzahl aller 'gold_reference'-Texte eines Textausschnitts.
    """
    return sum(count_words(req_data["gold_reference"]) for req_data in requirements.values() if req_data["gold_reference"])



def evaluate_dataset(json_file: str):

    global text_analysis_results
    data = dl.load_json_to_dict(json_file)

    if not data:
        print("No data found in JSON file.")
        return

    #print(f"\nâœ… Loaded {len(data)} text segments. Starting analysis...\n")

    for text_id, entry in data.items():
        original_text = entry["original_text"]
        requirements = entry["requirements"]

        num_chars = count_characters(original_text)
        num_words = count_words(original_text)
        num_references = len(requirements)
        reference_words = count_reference_words(requirements)
        non_reference_words = num_words - reference_words
        length_category = determine_length_category(num_words)


        # VerhÃ¤ltnisberechnungen
        ratio_reference_to_total = reference_words / num_words if num_words > 0 else 0
        ratio_nonref_to_total = non_reference_words / num_words if num_words > 0 else 0

        # Ergebnisse in dictionary speichern
        text_analysis_results[text_id] = {
            "source": entry["source"],
            "pages": entry["pages"],
            "num_chars": num_chars,
            "num_words": num_words,
            "num_references": num_references,
            "reference_words": reference_words,
            "non_reference_words": non_reference_words,
            "ratio_reference_to_total": round(ratio_reference_to_total, 2),
            "ratio_nonref_to_total": round(ratio_nonref_to_total, 2),
            "length_category": length_category
        }

    return text_analysis_results



def determine_length_category(num_words: int) -> int:
    """
    Bestimmt die LÃ¤ngenkategorie basierend auf der Wortanzahl des Textes.
    """
    if num_words < 10:
        return 0
    elif num_words >= 100:
        return 10
    else:
        return num_words // 10



def print_statistics():
    """Gibt grundlegende Statistiken Ã¼ber alle analysierten Textsegmente aus."""
    if not text_analysis_results:
        print("âš ï¸ Keine Analyseergebnisse vorhanden.")
        return

    df = pd.DataFrame.from_dict(text_analysis_results, orient="index")

    print("\nğŸ“Š Statistische Ãœbersicht Ã¼ber alle Textsegmente:\n")

    print(f"ğŸ”¢ Anzahl analysierter Textsegmente:      {len(df)}")
    print(f"ğŸ“ Gesamtanzahl Zeichen (original_text):  {df['num_chars'].sum()}")
    print(f"ğŸ“ Gesamtanzahl WÃ¶rter (original_text):   {df['num_words'].sum()}")
    print(f"ğŸ§© Gesamtanzahl Referenzen:               {df['num_references'].sum()}")
    print(f"ğŸ§© Gesamtanzahl Referenz-WÃ¶rter:          {df['reference_words'].sum()}")
    print(f"ğŸ“‰ Gesamtanzahl Nicht-Referenz-WÃ¶rter:    {df['non_reference_words'].sum()}")

    print("\nğŸ“ˆ Durchschnittswerte pro Textsegment:")
    print(f"â¡ï¸ Zeichen:              {df['num_chars'].mean():.2f}")
    print(f"â¡ï¸ WÃ¶rter:               {df['num_words'].mean():.2f}")
    print(f"â¡ï¸ Referenzen:           {df['num_references'].mean():.2f}")
    print(f"â¡ï¸ Referenz-WÃ¶rter:      {df['reference_words'].mean():.2f}")
    print(f"â¡ï¸ Nicht-Referenz-WÃ¶rter:{df['non_reference_words'].mean():.2f}")

    print("\nğŸ“ Min/Max-Werte (zur Orientierung):")
    print(f"ğŸ“ KÃ¼rzester Text (WÃ¶rter):   {df['num_words'].min()} | LÃ¤ngster Text: {df['num_words'].max()}")
    print(f"ğŸ”¢ Wenigste Referenzen:       {df['num_references'].min()} | Meiste: {df['num_references'].max()}")
    print(f"âœ‚ï¸ Geringste Ref-WÃ¶rter:      {df['reference_words'].min()} | Meiste: {df['reference_words'].max()}")



def print_groupwise_statistics(df: pd.DataFrame):
    """
    Gibt gruppierte Durchschnittswerte fÃ¼r definierte Textgruppen (alt: 1â€“20, 21â€“40, 41â€“60; neu: 1-40, 41-80, 81-120) aus.
    """

    # Gruppenspalte hinzufÃ¼gen
    df["gruppe"] = df.index.map(assign_group)

    grouped = df.groupby("gruppe")

    # Durchschnittswerte ausgeben
    print("\nğŸ“Š Gruppierte Durchschnittswerte (Textausschnitt-Gruppen):\n")
    print(grouped[[
        "num_words",
        "num_references",
        "reference_words",
        "non_reference_words",
        "ratio_reference_to_total",
        "ratio_nonref_to_total"
    ]].mean().round(2))

    # VollstÃ¤ndige Kennzahlen pro Gruppe
    for group_name, group_df in grouped:
        print(f"\nğŸ“˜ Gruppe {group_name} â€“ detaillierte Kennzahlen:\n")
        print(f"ğŸ”¢ Anzahl Textsegmente:         {len(group_df)}")
        print(f"ğŸ“ Gesamtanzahl Zeichen:       {group_df['num_chars'].sum()}")
        print(f"ğŸ“ Gesamtanzahl WÃ¶rter:        {group_df['num_words'].sum()}")
        print(f"ğŸ§© Gesamtanzahl Referenzen:    {group_df['num_references'].sum()}")
        print(f"ğŸ§© Referenz-WÃ¶rter gesamt:     {group_df['reference_words'].sum()}")
        print(f"ğŸ“‰ Nicht-Referenz-WÃ¶rter:      {group_df['non_reference_words'].sum()}")

        print(f"\nğŸ“ˆ Durchschnittswerte:")
        print(f"â¡ï¸ Zeichen:                    {group_df['num_chars'].mean():.2f}")
        print(f"â¡ï¸ WÃ¶rter:                     {group_df['num_words'].mean():.2f}")
        print(f"â¡ï¸ Referenzen:                 {group_df['num_references'].mean():.2f}")
        print(f"â¡ï¸ Referenz-WÃ¶rter:            {group_df['reference_words'].mean():.2f}")
        print(f"â¡ï¸ Nicht-Referenz-WÃ¶rter:      {group_df['non_reference_words'].mean():.2f}")

        print(f"\nğŸ“ Min/Max-Werte:")
        print(f"ğŸ“ KÃ¼rzester Text (WÃ¶rter):    {group_df['num_words'].min()} | LÃ¤ngster: {group_df['num_words'].max()}")
        print(f"ğŸ”¢ Wenigste Referenzen:        {group_df['num_references'].min()} | Meiste: {group_df['num_references'].max()}")
        print(f"âœ‚ï¸ Geringste Ref-WÃ¶rter:       {group_df['reference_words'].min()} | Meiste: {group_df['reference_words'].max()}")



def assign_group(text_id: str) -> str:
    number = int(text_id)
    if 1 <= number <= 40:
        return 1
    elif 41 <= number <= 80:
        return 2
    elif 81 <= number <= 120:
        return 3
    else:
        return 4



def print_length_category_distribution(df: pd.DataFrame):
    """
    Gibt die Verteilung der Textausschnitte Ã¼ber Wortanzahl-Kategorien aus (0â€“10), inkl. leerer Kategorien.
    """
    print("\nğŸ“ Kategorisierung nach TextlÃ¤nge (Wortanzahl):\n")

    # Alle mÃ¶glichen Kategorien von 0 bis 10
    all_categories = pd.Series(0, index=range(0, 11))

    # TatsÃ¤chliche ZÃ¤hlung
    actual_counts = df["length_category"].value_counts().sort_index()

    # Fehlende Kategorien ergÃ¤nzen mit 0
    category_counts = all_categories.add(actual_counts, fill_value=0).astype(int)

    # Ausgabe
    for category, count in category_counts.items():
        if category < 10:
            print(f"ğŸ—‚ï¸ Kategorie {category} (WÃ¶rter {category*10}â€“{category*10+9}): {count} ")
        else:
            print(f"ğŸ—‚ï¸ Kategorie {category} (WÃ¶rter â‰¥100): {count} ")



def print_length_category_distribution_by_group(df: pd.DataFrame):
    """
    Gibt die Verteilung der TextlÃ¤ngen-Kategorien fÃ¼r jede definierte Gruppe (1â€“3) separat aus.
    """
    print("\nğŸ“ Kategorisierung nach TextlÃ¤nge je Gruppe (Wortanzahl):\n")

    df["gruppe"] = df.index.map(assign_group)

    for group in sorted(df["gruppe"].unique()):
        group_df = df[df["gruppe"] == group]
        print(f"\nğŸ”¹ Gruppe {group}:")

        # Kategorien: 0â€“10
        all_categories = pd.Series(0, index=range(0, 11))
        actual_counts = group_df["length_category"].value_counts().sort_index()
        category_counts = all_categories.add(actual_counts, fill_value=0).astype(int)

        for category, count in category_counts.items():
            if category < 10:
                print(f"ğŸ—‚ï¸ Kategorie {category} (WÃ¶rter {category*10}â€“{category*10+9}): {count} ")
            else:
                print(f"ğŸ—‚ï¸ Kategorie {category} (WÃ¶rter â‰¥100): {count} ")



def export_full_summary_to_csv(df: pd.DataFrame):
    """
    Exportiert alle Konsolenmetriken in eine strukturierte CSV-Datei.
    """

    df["gruppe"] = df.index.map(assign_group)
    output_rows = []

    # ğŸ”¢ Globale Gesamtwerte
    output_rows.append({"Kategorie": "ğŸ”¢ Anzahl analysierter Textsegmente", "Wert": len(df)})
    output_rows.append({"Kategorie": "ğŸ“ Gesamtanzahl Zeichen (original_text)", "Wert": df['num_chars'].sum()})
    output_rows.append({"Kategorie": "ğŸ“ Gesamtanzahl WÃ¶rter (original_text)", "Wert": df['num_words'].sum()})
    output_rows.append({"Kategorie": "ğŸ§© Gesamtanzahl Referenzen", "Wert": df['num_references'].sum()})
    output_rows.append({"Kategorie": "ğŸ§© Gesamtanzahl Referenz-WÃ¶rter", "Wert": df['reference_words'].sum()})
    output_rows.append({"Kategorie": "ğŸ“‰ Gesamtanzahl Nicht-Referenz-WÃ¶rter", "Wert": df['non_reference_words'].sum()})

    output_rows.append({})
    output_rows.append({"Kategorie": "ğŸ“ˆ Durchschnittswerte pro Textsegment"})
    output_rows.append({"Kategorie": "â¡ï¸ Zeichen", "Wert": round(df['num_chars'].mean(), 2)})
    output_rows.append({"Kategorie": "â¡ï¸ WÃ¶rter", "Wert": round(df['num_words'].mean(), 2)})
    output_rows.append({"Kategorie": "â¡ï¸ Referenzen", "Wert": round(df['num_references'].mean(), 2)})
    output_rows.append({"Kategorie": "â¡ï¸ Referenz-WÃ¶rter", "Wert": round(df['reference_words'].mean(), 2)})
    output_rows.append({"Kategorie": "â¡ï¸ Nicht-Referenz-WÃ¶rter", "Wert": round(df['non_reference_words'].mean(), 2)})

    output_rows.append({})
    output_rows.append({"Kategorie": "ğŸ“ Min/Max-Werte"})
    output_rows.append({"Kategorie": "ğŸ“ KÃ¼rzester Text (WÃ¶rter)", "Wert": df['num_words'].min()})
    output_rows.append({"Kategorie": "ğŸ“ LÃ¤ngster Text (WÃ¶rter)", "Wert": df['num_words'].max()})
    output_rows.append({"Kategorie": "ğŸ”¢ Wenigste Referenzen", "Wert": df['num_references'].min()})
    output_rows.append({"Kategorie": "ğŸ”¢ Meiste Referenzen", "Wert": df['num_references'].max()})
    output_rows.append({"Kategorie": "âœ‚ï¸ Geringste Ref-WÃ¶rter", "Wert": df['reference_words'].min()})
    output_rows.append({"Kategorie": "âœ‚ï¸ Meiste Ref-WÃ¶rter", "Wert": df['reference_words'].max()})

    # ğŸ“ Kategorisierung nach TextlÃ¤nge
    output_rows.append({})
    output_rows.append({"Kategorie": "ğŸ“ Kategorisierung nach TextlÃ¤nge (Wortanzahl)"})
    category_counts = df['length_category'].value_counts().reindex(range(0, 11), fill_value=0).sort_index()
    for cat, count in category_counts.items():
        cat_range = f"{cat*10}â€“{cat*10+9}" if cat < 10 else "â‰¥100"
        output_rows.append({"Kategorie": f"ğŸ—‚ï¸ Kategorie {cat} (WÃ¶rter {cat_range})", "Wert": count})

    # ğŸ“Š Gruppierte Durchschnittswerte
    grouped = df.groupby("gruppe")
    output_rows.append({})
    output_rows.append({"Kategorie": "ğŸ“Š Gruppierte Durchschnittswerte"})

    for group, gdf in grouped:
        output_rows.append({})
        output_rows.append({"Kategorie": f"ğŸ“˜ Gruppe {group} â€“ Gesamtsummen"})
        output_rows.append({"Kategorie": "Anzahl Textsegmente", "Wert": len(gdf)})
        output_rows.append({"Kategorie": "Zeichen gesamt", "Wert": gdf['num_chars'].sum()})
        output_rows.append({"Kategorie": "WÃ¶rter gesamt", "Wert": gdf['num_words'].sum()})
        output_rows.append({"Kategorie": "Referenzen gesamt", "Wert": gdf['num_references'].sum()})
        output_rows.append({"Kategorie": "Referenz-WÃ¶rter gesamt", "Wert": gdf['reference_words'].sum()})
        output_rows.append({"Kategorie": "Nicht-Referenz-WÃ¶rter", "Wert": gdf['non_reference_words'].sum()})

        output_rows.append({"Kategorie": f"ğŸ“˜ Gruppe {group} â€“ Durchschnittswerte"})
        output_rows.append({"Kategorie": "Ã˜ Zeichen", "Wert": round(gdf['num_chars'].mean(), 2)})
        output_rows.append({"Kategorie": "Ã˜ WÃ¶rter", "Wert": round(gdf['num_words'].mean(), 2)})
        output_rows.append({"Kategorie": "Ã˜ Referenzen", "Wert": round(gdf['num_references'].mean(), 2)})
        output_rows.append({"Kategorie": "Ã˜ Ref-WÃ¶rter", "Wert": round(gdf['reference_words'].mean(), 2)})
        output_rows.append({"Kategorie": "Ã˜ NonRef-WÃ¶rter", "Wert": round(gdf['non_reference_words'].mean(), 2)})

        output_rows.append({"Kategorie": "Ã˜ Ref/Total", "Wert": f"{gdf['ratio_reference_to_total'].mean():.2%}"})
        output_rows.append({"Kategorie": "Ã˜ NonRef/Total", "Wert": f"{gdf['ratio_nonref_to_total'].mean():.2%}"})

        output_rows.append({"Kategorie": f"ğŸ“˜ Gruppe {group} â€“ Min/Max"})
        output_rows.append({"Kategorie": "KÃ¼rzester Text (WÃ¶rter)", "Wert": gdf['num_words'].min()})
        output_rows.append({"Kategorie": "LÃ¤ngster Text (WÃ¶rter)", "Wert": gdf['num_words'].max()})
        output_rows.append({"Kategorie": "Min Referenzen", "Wert": gdf['num_references'].min()})
        output_rows.append({"Kategorie": "Max Referenzen", "Wert": gdf['num_references'].max()})
        output_rows.append({"Kategorie": "Min Ref-WÃ¶rter", "Wert": gdf['reference_words'].min()})
        output_rows.append({"Kategorie": "Max Ref-WÃ¶rter", "Wert": gdf['reference_words'].max()})

        # Kategorie-Auswertung pro Gruppe
        group_categories = gdf['length_category'].value_counts().reindex(range(0, 11), fill_value=0).sort_index()
        for cat, count in group_categories.items():
            cat_range = f"{cat*10}â€“{cat*10+9}" if cat < 10 else "â‰¥100"
            output_rows.append({"Kategorie": f"ğŸ—‚ï¸ Gruppe {group} â€“ Kategorie {cat} (WÃ¶rter {cat_range})", "Wert": count})

    # Export
    summary_df = pd.DataFrame(output_rows)
    summary_df.to_csv("text_analysis_summary.csv", index=False)
    print("\nğŸ“„ AusfÃ¼hrlicher Bericht wurde in 'text_analysis_summary.csv' gespeichert.")



def main():
    """
    Main function to start the evaluation process.
    """
    json_file = "BenchmarkRequirements.json"  # Adjust the path if necessary
    evaluate_dataset(json_file)

    # Ausgabe als DataFrame
    df = pd.DataFrame.from_dict(text_analysis_results, orient="index")
    print("\nğŸ“Š Analyse abgeschlossen. Ãœbersicht:\n")
    print(df)

    # Optional: als CSV speichern
    df.to_csv("text_analysis_results.csv", index_label="text_id")
    print("\nğŸ’¾ Ergebnisse wurden in 'text_analysis_results.csv' gespeichert.")

    # Statistikfunktion
    print_statistics()
    print_length_category_distribution(df)

    # Gruppierte Auswertung
    print_groupwise_statistics(df)

    # Gruppierte Kategorisierung
    print_length_category_distribution_by_group(df)

    # Zusammenfassung in zweiter CSV-Datei
    export_full_summary_to_csv(df)



if __name__ == "__main__":
    main()    